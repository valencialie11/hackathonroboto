{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# NLP Package\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.corpus import words\n",
    "  \n",
    "# Misc.\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hello World in Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960353321</td>\n",
       "      <td>@bex_1210 holy crap, I need to see that! Too b...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1753218598</td>\n",
       "      <td>HAPPY MOTHER'S DAY to all of the wonderful wom...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1961368089</td>\n",
       "      <td>Wishing I could be in NOLA this weekend  oh we...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1961456147</td>\n",
       "      <td>What a day! #dayofservice completed, and now a...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962477969</td>\n",
       "      <td>@JamesMurphy anything to sell an album. poor t...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                            content sentiment\n",
       "0  1960353321  @bex_1210 holy crap, I need to see that! Too b...     happy\n",
       "1  1753218598  HAPPY MOTHER'S DAY to all of the wonderful wom...     happy\n",
       "2  1961368089  Wishing I could be in NOLA this weekend  oh we...     happy\n",
       "3  1961456147  What a day! #dayofservice completed, and now a...     happy\n",
       "4  1962477969  @JamesMurphy anything to sell an album. poor t...       sad"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>1957523762</td>\n",
       "      <td>I have been playing skate for two hours. Now i...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>1965999020</td>\n",
       "      <td>im wearing a certain tye dye tshirt at the mom...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>1694258339</td>\n",
       "      <td>@DeepaPrabhu Thanks and thanks</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>1964535265</td>\n",
       "      <td>@scottisafool  I had a analog tuner the MC tea...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>1962064791</td>\n",
       "      <td>Just watched the &amp;quot;Final Break&amp;quot; final...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                            content sentiment\n",
       "23995  1957523762  I have been playing skate for two hours. Now i...     happy\n",
       "23996  1965999020  im wearing a certain tye dye tshirt at the mom...       sad\n",
       "23997  1694258339                     @DeepaPrabhu Thanks and thanks     happy\n",
       "23998  1964535265  @scottisafool  I had a analog tuner the MC tea...       sad\n",
       "23999  1962064791  Just watched the &quot;Final Break&quot; final...     happy"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels= 'id', axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@bex_1210 holy crap, I need to see that! Too b...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAPPY MOTHER'S DAY to all of the wonderful wom...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wishing I could be in NOLA this weekend  oh we...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What a day! #dayofservice completed, and now a...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@JamesMurphy anything to sell an album. poor t...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentiment\n",
       "0  @bex_1210 holy crap, I need to see that! Too b...     happy\n",
       "1  HAPPY MOTHER'S DAY to all of the wonderful wom...     happy\n",
       "2  Wishing I could be in NOLA this weekend  oh we...     happy\n",
       "3  What a day! #dayofservice completed, and now a...     happy\n",
       "4  @JamesMurphy anything to sell an album. poor t...       sad"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy      9180\n",
       "sad        8174\n",
       "neutral    5786\n",
       "fury        860\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = df['sentiment']\n",
    "sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.countplot(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw exploration\n",
    "corpus = []\n",
    "for content in df['content']:\n",
    "    corpus.append(content)\n",
    "corpus = ' '.join(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word/Character/Symbol/Anything count in corpus: 1795146\n"
     ]
    }
   ],
   "source": [
    "print('Word/Character/Symbol/Anything count in corpus:', len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 329309\n",
      "Number of unique tokens: 56965\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "def tokenizer(text):\n",
    "    return text.split(' ')\n",
    "\n",
    "tokenised_corpus = tokenizer(corpus)\n",
    "print('Number of tokens:', len(tokenised_corpus))\n",
    "tokenised_unique = set(tokenised_corpus)\n",
    "print('Number of unique tokens:', len(tokenised_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('relaxful', 1),\n",
       " ('#dayofservice', 1),\n",
       " ('completed,', 1),\n",
       " ('Clearing', 1),\n",
       " ('Splitting', 1),\n",
       " ('@JamesMurphy', 1),\n",
       " ('@PRChels_BE', 1),\n",
       " ('Yellow', 1),\n",
       " ('Maybes', 1),\n",
       " ('Chelk.', 1),\n",
       " ('@SQLChicken', 1),\n",
       " ('Tail', 1),\n",
       " ('legs!', 1),\n",
       " ('@dpbkmb', 1),\n",
       " ('@prateek_agwl', 1),\n",
       " ('whom?', 1),\n",
       " (\"'Shah\", 1),\n",
       " ('Rukh', 1),\n",
       " (\"Khan'\", 1),\n",
       " ('imposter', 1),\n",
       " ('follow...', 1),\n",
       " ('@laurarenee411', 1),\n",
       " ('core.', 1),\n",
       " ('@Tyrese4ReaL', 1),\n",
       " ('Dean!', 1),\n",
       " ('breathe!', 1),\n",
       " ('@dever', 1),\n",
       " ('orbits-gravity-moon-space', 1),\n",
       " ('exploration-galaxy-exoplanets-universe-life', 1),\n",
       " ('earth-idea', 1),\n",
       " ('Gods-religions-philosophy-morality', 1),\n",
       " ('@miss_k_renee', 1),\n",
       " ('Different', 1),\n",
       " ('position!', 1),\n",
       " ('@AdamTheStudent', 1),\n",
       " ('gather?!', 1),\n",
       " ('@joyntheir', 1),\n",
       " ('keyboard.', 1),\n",
       " ('care!', 1),\n",
       " ('hallo', 1),\n",
       " ('@questredactie', 1),\n",
       " ('(2', 1),\n",
       " ('authors', 1),\n",
       " ('co-workers!', 1),\n",
       " ('@mohandoss', 1),\n",
       " (\"'17\", 1),\n",
       " (\"Again'.\", 1),\n",
       " ('@QueenofKong', 1),\n",
       " ('@gleannignacio', 1),\n",
       " ('17:00', 1),\n",
       " ('@Cleric20', 1),\n",
       " ('tonite!!', 1),\n",
       " ('idk...I', 1),\n",
       " ('horrible...and', 1),\n",
       " ('suspicious', 1),\n",
       " ('days,but', 1),\n",
       " ('TGIF...', 1),\n",
       " ('parts.', 1),\n",
       " ('@cybercabz', 1),\n",
       " ('lookie,', 1),\n",
       " ('loveeeeee', 1),\n",
       " ('lifestyle!', 1),\n",
       " ('@francecino', 1),\n",
       " ('agaiiiiin', 1),\n",
       " ('caterpillar', 1),\n",
       " ('reflexology', 1),\n",
       " ('@the_real_nash', 1),\n",
       " ('honorary', 1),\n",
       " ('@daxvelando!', 1),\n",
       " ('Hockey', 1),\n",
       " ('fukinï¿½', 1),\n",
       " ('hole!', 1),\n",
       " ('@NickMLTM', 1),\n",
       " ('hardcore!', 1),\n",
       " ('@againtoday', 1),\n",
       " ('9-12', 1),\n",
       " ('frustrating', 1),\n",
       " ('Legend', 1),\n",
       " ('Inotia', 1),\n",
       " ('??????.', 1),\n",
       " ('???????.', 1),\n",
       " ('31?', 1),\n",
       " ('???.', 1),\n",
       " ('@savepolaroid', 1),\n",
       " ('#roidweek', 1),\n",
       " ('@kristenyt', 1),\n",
       " ('there...To', 1),\n",
       " ('Blackberries', 1),\n",
       " ('@underhill70', 1),\n",
       " ('@ileanedover', 1),\n",
       " ('HEYHEYHEYY', 1),\n",
       " ('watcha', 1),\n",
       " ('friday?', 1),\n",
       " ('`private', 1),\n",
       " ('@MasterSavage', 1),\n",
       " ('everythings', 1),\n",
       " ('Comp.', 1),\n",
       " ('Mental', 1),\n",
       " ('Samuel', 1),\n",
       " ('@alex_navarro', 1),\n",
       " ('grub.', 1),\n",
       " ('eventful', 1),\n",
       " ('Ian,', 1),\n",
       " ('@InNoSenseLost', 1),\n",
       " ('harm', 1),\n",
       " ('@amystow', 1),\n",
       " ('@2oceansvibe', 1),\n",
       " ('errrr...', 1),\n",
       " ('V.Luna', 1),\n",
       " ('Wicked,', 1),\n",
       " ('DVB-S', 1),\n",
       " ('FA', 1),\n",
       " ('collectors', 1),\n",
       " ('@burnspank41', 1),\n",
       " ('theyr', 1),\n",
       " ('@katecameron2002', 1),\n",
       " ('@ukrainiac', 1),\n",
       " ('Ukrainian!', 1),\n",
       " ('181', 1),\n",
       " ('cameraphone', 1),\n",
       " ('@Molltini', 1),\n",
       " ('&quot;Quirky', 1),\n",
       " ('Q&quot;', 1),\n",
       " ('cue', 1),\n",
       " ('concerto', 1),\n",
       " ('Arrr.', 1),\n",
       " ('bwahahaha..', 1),\n",
       " ('btw!!', 1),\n",
       " ('@WilHarris', 1),\n",
       " ('http://tinyurl.com/q3u32x', 1),\n",
       " ('podcasting', 1),\n",
       " ('bit-tech?', 1),\n",
       " ('@wendica', 1),\n",
       " ('checked.', 1),\n",
       " ('@StaciJShelton', 1),\n",
       " ('Aladdin?', 1),\n",
       " ('murderin', 1),\n",
       " ('@whiteangle', 1),\n",
       " ('Darcy', 1),\n",
       " ('@davidchua', 1),\n",
       " ('psp', 1),\n",
       " ('pokemons.', 1),\n",
       " ('@Tacquira', 1),\n",
       " ('love..you', 1),\n",
       " ('nyc,', 1),\n",
       " ('Jessicaaaa.', 1),\n",
       " (\"lightner's\", 1),\n",
       " ('crib.', 1),\n",
       " ('@cocotteloup', 1),\n",
       " ('difference!!', 1),\n",
       " ('@OfficialAshleyG', 1),\n",
       " ('alice,', 1),\n",
       " ('Indians', 1),\n",
       " ('bucks??', 1),\n",
       " ('http://plurk.com/p/rpaag', 1),\n",
       " ('ginormous', 1),\n",
       " ('@mytvnetwork', 1),\n",
       " ('pansy', 1),\n",
       " ('codeh?!', 1),\n",
       " ('o,', 1),\n",
       " ('@MrSucre', 1),\n",
       " ('did!!!', 1),\n",
       " ('@digicho', 1),\n",
       " (\"Chaz's\", 1),\n",
       " ('Daily', 1),\n",
       " ('Happenings:', 1),\n",
       " ('22:31', 1),\n",
       " ('11:09', 1),\n",
       " ('#..', 1),\n",
       " ('http://tinyurl.com/lgwrum', 1),\n",
       " ('@librariansti', 1),\n",
       " ('somewhere.&quot;', 1),\n",
       " ('ds', 1),\n",
       " ('lite!', 1),\n",
       " ('ha...just', 1),\n",
       " ('cocktail:', 1),\n",
       " ('Dances', 1),\n",
       " ('Wenches', 1),\n",
       " ('(Cranberry', 1),\n",
       " ('Juice,', 1),\n",
       " ('Spiced', 1),\n",
       " ('Rum),', 1),\n",
       " ('cranberry', 1),\n",
       " ('@LILBOOTY24', 1),\n",
       " ('borrowing', 1),\n",
       " ('today..i', 1),\n",
       " ('Ryder', 1),\n",
       " ('playgroup', 1),\n",
       " ('Ghostwhisperer', 1),\n",
       " ('weather!!!!', 1),\n",
       " ('conclusion', 1),\n",
       " ('lemongrass', 1),\n",
       " ('lysol', 1),\n",
       " ('t...', 1),\n",
       " ('http://is.gd/JmjB', 1),\n",
       " ('angry.', 1),\n",
       " ('70??', 1),\n",
       " ('@tursiops718', 1),\n",
       " ('Ohnoes!', 1),\n",
       " ('icky!', 1),\n",
       " ('heyheyheyheyehyeyyyyyyyyyyyyyyyy', 1),\n",
       " ('tokio', 1),\n",
       " ('friad', 1),\n",
       " ('@jason_2008', 1),\n",
       " ('gardening,', 1),\n",
       " ('hoovering', 1),\n",
       " ('warcraft', 1),\n",
       " ('@deberito', 1),\n",
       " (\"Beto's\", 1),\n",
       " ('Pizzeria', 1),\n",
       " ('Banksville', 1),\n",
       " ('Rd', 1),\n",
       " ('Beachview', 1),\n",
       " ('area...', 1),\n",
       " ('@prayingmother', 1),\n",
       " ('recomended', 1),\n",
       " ('@scorpfromhell', 1),\n",
       " ('channels.', 1),\n",
       " ('search.', 1),\n",
       " ('@Katizzle', 1),\n",
       " ('awards..but', 1),\n",
       " ('link?', 1),\n",
       " ('thaank', 1),\n",
       " ('@shanenassiri', 1),\n",
       " ('Flashpoints', 1),\n",
       " ('http//:www.kpfa.org', 1),\n",
       " ('@norabf', 1),\n",
       " ('segment', 1),\n",
       " ('Chevron', 1),\n",
       " ('hayfevery', 1),\n",
       " ('sufferin', 1),\n",
       " ('@ZaraGreen', 1),\n",
       " ('@chocoshabi', 1),\n",
       " ('Waldi.', 1),\n",
       " ('keyword', 1),\n",
       " ('@Sharmi', 1),\n",
       " ('hues', 1),\n",
       " ('birdied', 1),\n",
       " ('figured.', 1),\n",
       " ('manga', 1),\n",
       " ('Heyy.thnxx.or.inviting.me.to.ur.party.rob.ill.be.down.there.on.june.24th.ill.miss.u.when.u.go.to.italy....',\n",
       "  1),\n",
       " ('&lt;333333333', 1),\n",
       " ('txt.me.hon!!!', 1),\n",
       " ('Goooooodmoring', 1),\n",
       " ('YAT', 1),\n",
       " ('@its_aygee', 1),\n",
       " ('Feds,', 1),\n",
       " ('hounding', 1),\n",
       " ('dodged', 1),\n",
       " ('@zaktar', 1),\n",
       " ('change?', 1),\n",
       " ('@akarra', 1),\n",
       " ('&quot;picky&quot;', 1),\n",
       " ('(=precise)', 1),\n",
       " ('innabit', 1),\n",
       " ('@lowestformofwit', 1),\n",
       " ('@simoncurtis', 1),\n",
       " ('...Your', 1),\n",
       " ('Hotter', 1),\n",
       " ('@Phlupp', 1),\n",
       " ('@Malunis', 1),\n",
       " ('mods,', 1),\n",
       " ('@Artoni', 1),\n",
       " ('saw.', 1),\n",
       " (\"mine's\", 1),\n",
       " ('@pkBLGdonahue', 1),\n",
       " ('wellllll,', 1),\n",
       " ('editing.', 1),\n",
       " ('@keylahtia', 1),\n",
       " ('vmail', 1),\n",
       " ('CALLED', 1),\n",
       " ('store..', 1),\n",
       " ('@hnnhmllr', 1),\n",
       " ('non-stop?', 1),\n",
       " ('@pandamachinne', 1),\n",
       " ('@__Greer__', 1),\n",
       " ('Greer!', 1),\n",
       " ('Marco!', 1),\n",
       " ('actor(ress)', 1),\n",
       " ('Gatorade', 1),\n",
       " ('yumyum', 1),\n",
       " ('arise', 1),\n",
       " ('poppy', 1),\n",
       " ('ill,', 1),\n",
       " ('@ChontelleBourke', 1),\n",
       " ('walks', 1),\n",
       " ('May!', 1),\n",
       " ('500.', 1),\n",
       " ('horrors', 1),\n",
       " ('1973,', 1),\n",
       " ('captive', 1),\n",
       " (\"Indy's\", 1),\n",
       " ('spirit...', 1),\n",
       " ('@celldweller', 1),\n",
       " ('Must...', 1),\n",
       " ('have...', 1),\n",
       " ('music...', 1),\n",
       " ('Chapter', 1),\n",
       " ('Hurry!', 1),\n",
       " ('@Lealala', 1),\n",
       " ('Wesley', 1),\n",
       " ('WON!', 1),\n",
       " ('Sucks.', 1),\n",
       " ('jb', 1),\n",
       " ('dread', 1),\n",
       " ('3lbs', 1),\n",
       " ('@sunvitd', 1),\n",
       " ('@gosner', 1),\n",
       " ('harlem,', 1),\n",
       " ('lived.', 1),\n",
       " ('english,', 1),\n",
       " ('@jennywoo42', 1),\n",
       " ('(although', 1),\n",
       " ('p.r.!!', 1),\n",
       " ('@Miss_Molotov', 1),\n",
       " ('bamboo?', 1),\n",
       " ('sense?', 1),\n",
       " ('pass?', 1),\n",
       " ('Bread.', 1),\n",
       " ('@badlady', 1),\n",
       " ('win7', 1),\n",
       " ('thermal', 1),\n",
       " ('management...75c', 1),\n",
       " ('gpu', 1),\n",
       " ('Jacqueline', 1),\n",
       " ('Wilson', 1),\n",
       " ('CBBC', 1),\n",
       " ('many..', 1),\n",
       " ('webdesign', 1),\n",
       " ('@lizridley', 1),\n",
       " ('text?', 1),\n",
       " ('@lisam75', 1),\n",
       " ('ticketless', 1),\n",
       " ('@jonoble', 1),\n",
       " ('editions', 1),\n",
       " ('@PhotosbyLee', 1),\n",
       " ('chips?', 1),\n",
       " ('@vmysterrr', 1),\n",
       " ('serious!?', 1),\n",
       " ('bloooooows', 1),\n",
       " ('@MyCaribbeanFood', 1),\n",
       " ('Mysore!', 1),\n",
       " ('Thankfully,', 1),\n",
       " ('pigs/swines!', 1),\n",
       " ('@crafty', 1),\n",
       " ('comfort(able', 1),\n",
       " ('world)', 1),\n",
       " ('PhD', 1),\n",
       " ('form-filling-in', 1),\n",
       " ('@Potato_Chip', 1),\n",
       " ('summer!!', 1),\n",
       " ('*moment', 1),\n",
       " ('silence*', 1),\n",
       " ('Budget', 1),\n",
       " ('wayyy', 1),\n",
       " ('$$$....', 1),\n",
       " ('Budget?!?!', 1),\n",
       " ('ful', 1),\n",
       " ('rasberries', 1),\n",
       " ('grapes,', 1),\n",
       " ('@edincoat', 1),\n",
       " ('@loveyoumoreMJ', 1),\n",
       " ('Skylit', 1),\n",
       " (\"Drive's\", 1),\n",
       " ('raining...', 1),\n",
       " ('haaaate', 1),\n",
       " ('violin', 1),\n",
       " ('lesson&lt;3', 1),\n",
       " ('KAYLEN', 1),\n",
       " ('FINNA', 1),\n",
       " ('BORED', 1),\n",
       " ('WEEKEND!!!', 1),\n",
       " ('UUURGG', 1),\n",
       " ('SPEND', 1),\n",
       " ('SHOPPING', 1),\n",
       " ('socks...', 1),\n",
       " ('@xoxobb11', 1),\n",
       " ('done??', 1),\n",
       " ('labs?', 1),\n",
       " ('Keswick', 1),\n",
       " ('@anntorrence', 1),\n",
       " ('@jeremyhall', 1),\n",
       " ('photowalkingutah', 1),\n",
       " ('photowalks?', 1),\n",
       " ('Maggie.', 1),\n",
       " ('@kyla_durden', 1),\n",
       " ('@sizzlemaker', 1),\n",
       " (\"Mel's\", 1),\n",
       " ('eyes.....', 1),\n",
       " ('*swoons', 1),\n",
       " ('it*', 1),\n",
       " ('@Atomik', 1),\n",
       " ('http://blip.fm/~5jehr', 1),\n",
       " ('@LindseyJaffe', 1),\n",
       " ('TweetHampton,', 1),\n",
       " ('congrats!!', 1),\n",
       " ('http://openzap.com/', 1),\n",
       " ('list)', 1),\n",
       " ('@tom_pollard', 1),\n",
       " ('Never.', 1),\n",
       " ('banned', 1),\n",
       " ('@xombie', 1),\n",
       " ('NO.', 1),\n",
       " ('ask.', 1),\n",
       " ('@love_Jamie', 1),\n",
       " ('@LarissaBootz', 1),\n",
       " ('@doeko', 1),\n",
       " ('rox', 1),\n",
       " ('http://twitpic.com/4woxf', 1),\n",
       " ('plane..', 1),\n",
       " ('t-shirt', 1),\n",
       " ('studio!', 1),\n",
       " ('@annhamilton', 1),\n",
       " ('Bogie', 1),\n",
       " ('@kouzrah', 1),\n",
       " ('etherreal', 1),\n",
       " ('preoccupation.', 1),\n",
       " (\"EtherREAL's\", 1),\n",
       " ('preoccupation...', 1),\n",
       " ('humm...', 1),\n",
       " ('schizophrenic', 1),\n",
       " ('http://bit.ly/19OL1b', 1),\n",
       " ('mower', 1),\n",
       " ('http://bit.ly/jdk0Z', 1),\n",
       " ('@Toongen', 1),\n",
       " ('@turtleclansago', 1),\n",
       " ('msg!', 1),\n",
       " ('singing!', 1),\n",
       " ('@Trillian711', 1),\n",
       " ('4k', 1),\n",
       " ('leftover', 1),\n",
       " ('dominos.', 1),\n",
       " ('Noiiiiice', 1),\n",
       " ('@joelhouston', 1),\n",
       " ('@stuntazian', 1),\n",
       " ('blues?', 1),\n",
       " ('@andmegansaid', 1),\n",
       " ('HIMYM', 1),\n",
       " ('@Jenshwa', 1),\n",
       " ('@FreshAssNess', 1),\n",
       " ('#iloveyou', 1),\n",
       " ('MA...', 1),\n",
       " ('leave!', 1),\n",
       " ('@cherylsayshi', 1),\n",
       " ('scattegories', 1),\n",
       " ('Joel,', 1),\n",
       " ('@codelust', 1),\n",
       " ('@prolificd', 1),\n",
       " ('vietnam', 1),\n",
       " ('forever..', 1),\n",
       " ('soooon', 1),\n",
       " ('likely.', 1),\n",
       " ('eat...poor', 1),\n",
       " ('hilly', 1),\n",
       " ('forget:', 1),\n",
       " ('Mommy?', 1),\n",
       " ('@jessicagee7', 1),\n",
       " ('restricted', 1),\n",
       " ('priviledges...', 1),\n",
       " ('@KashiMae', 1),\n",
       " ('Kashi!', 1),\n",
       " ('disservice', 1),\n",
       " ('ughhh!', 1),\n",
       " ('nuts...WONT', 1),\n",
       " ('DOWNLOAD', 1),\n",
       " ('PROFILE', 1),\n",
       " ('PIC!!', 1),\n",
       " ('...guess', 1),\n",
       " ('@rockingla', 1),\n",
       " ('@roboreese', 1),\n",
       " ('Mandy,', 1),\n",
       " ('Bff', 1),\n",
       " ('@penreyes', 1),\n",
       " ('Doogie', 1),\n",
       " ('Howser', 1),\n",
       " ('Log.', 1),\n",
       " ('23,', 1),\n",
       " ('Wrath', 1),\n",
       " ('Government', 1),\n",
       " ('Krista.', 1),\n",
       " ('AP:', 1),\n",
       " ('opt', 1),\n",
       " ('devastating', 1),\n",
       " ('assault...', 1),\n",
       " ('http://tinyurl.com/nmg9ht', 1),\n",
       " ('@Drudge_Report)', 1),\n",
       " ('@ChEmIcALbUlLeTs', 1),\n",
       " ('hives', 1),\n",
       " ('arms.', 1),\n",
       " ('Jayden!', 1),\n",
       " ('THINGS', 1),\n",
       " ('W/FAITH!!!!', 1),\n",
       " ('@letteapplejuice', 1),\n",
       " ('heckitty', 1),\n",
       " ('@deangeloredman', 1),\n",
       " ('Him!', 1),\n",
       " ('(deangeloredman', 1),\n",
       " ('http://ustre.am/2NlC)', 1),\n",
       " ('@MichaelNi', 1),\n",
       " ('fries!', 1),\n",
       " ('blip.tv', 1),\n",
       " ('@boomerous', 1),\n",
       " ('Discrimination', 1),\n",
       " ('XBL.', 1),\n",
       " ('manage.', 1),\n",
       " ('sometime.', 1),\n",
       " ('Hanami', 1),\n",
       " ('@debtguide', 1),\n",
       " ('Guide..', 1),\n",
       " ('Tip..', 1),\n",
       " ('mx', 1),\n",
       " ('@vhcoffee', 1),\n",
       " ('@Cubikmusik', 1),\n",
       " ('borin', 1),\n",
       " ('@SerendipityJane', 1),\n",
       " ('book!', 1),\n",
       " ('@Wally_v10', 1),\n",
       " ('grax', 1),\n",
       " ('@icebergstorm', 1),\n",
       " ('primatech,', 1),\n",
       " (\"handle's\", 1),\n",
       " ('decade', 1),\n",
       " ('@ModelTheany', 1),\n",
       " ('beefin....what', 1),\n",
       " ('leavin????', 1),\n",
       " ('wacko...loves', 1),\n",
       " ('Twello', 1),\n",
       " ('Foodie', 1),\n",
       " ('@josepicardo', 1),\n",
       " ('cooking?', 1),\n",
       " ('Sounds..', 1),\n",
       " ('http://tinyurl.com/qz88co', 1),\n",
       " ('@kidkierain', 1),\n",
       " ('Cobra,', 1),\n",
       " ('hub/gay', 1),\n",
       " ('bar,', 1),\n",
       " ('FREEZE', 1),\n",
       " ('FRAME', 1),\n",
       " ('ahhh!!!!', 1),\n",
       " ('sucks???', 1),\n",
       " ('toe!!', 1),\n",
       " ('OUCH!!', 1),\n",
       " ('fuk', 1),\n",
       " ('pack,', 1),\n",
       " (\"Mami's\", 1),\n",
       " (\"bringin'\", 1),\n",
       " ('@donomo', 1),\n",
       " ('twittpic', 1),\n",
       " ('p.', 1),\n",
       " ('Diddy', 1),\n",
       " ('@Jennajmsn', 1),\n",
       " ('Jenna.', 1),\n",
       " ('York!!!', 1),\n",
       " ('@getemgirlfriday', 1),\n",
       " ('Sisterhood', 1),\n",
       " ('Traveling', 1),\n",
       " ('Mars', 1),\n",
       " ('Bars', 1),\n",
       " ('@superficialgirl', 1),\n",
       " ('sandwich..', 1),\n",
       " ('olives', 1),\n",
       " ('maltese', 1),\n",
       " ('guinea', 1),\n",
       " ('pig.', 1),\n",
       " ('Stalin', 1),\n",
       " ('chillaxin', 1),\n",
       " ('BankHoliday,', 1),\n",
       " ('everbody', 1),\n",
       " ('wkend!', 1),\n",
       " ('@flyguyvan', 1),\n",
       " ('spayed', 1),\n",
       " ('trained', 1),\n",
       " ('@WParenthetical', 1),\n",
       " ('playstation!', 1),\n",
       " ('controllers', 1),\n",
       " ('hearts.', 1),\n",
       " ('Incase', 1),\n",
       " ('@moodleman', 1),\n",
       " (\"@bing's\", 1),\n",
       " ('7500', 1),\n",
       " ('circle!', 1),\n",
       " ('Glee', 1),\n",
       " ('@vautlapeine', 1),\n",
       " ('ahugs', 1),\n",
       " ('@piraja', 1),\n",
       " ('dohh!', 1),\n",
       " ('@MandyAlwaysKnws', 1),\n",
       " ('@Kikirowr', 1),\n",
       " ('mornings.', 1),\n",
       " ('@alexholroyd', 1),\n",
       " (\"bustin'\", 1),\n",
       " ('chops;', 1),\n",
       " ('appeal', 1),\n",
       " ('poop.', 1),\n",
       " ('Assignment', 1),\n",
       " ('decent....so', 1),\n",
       " ('@mikeavila', 1),\n",
       " ('ack!', 1),\n",
       " ('accounting', 1),\n",
       " ('stake', 1),\n",
       " ('milkshakes', 1),\n",
       " ('@PatriciaP1977', 1),\n",
       " ('@BackpackingDad', 1),\n",
       " ('Whooo', 1),\n",
       " ('Baby!', 1),\n",
       " ('co', 1),\n",
       " ('xo*blair', 1),\n",
       " ('@jvfriedman', 1),\n",
       " ('lunchtime.', 1),\n",
       " ('@daisydelfina', 1),\n",
       " ('ubertwitter...it', 1),\n",
       " ('locations!', 1),\n",
       " ('uber,', 1),\n",
       " ('@lostintheforest', 1),\n",
       " ('Remember', 1),\n",
       " ('SAE', 1),\n",
       " ('profy!,.just', 1),\n",
       " ('me!,.ayt!?,.lol!,.http://bit.ly/UsPlN', 1),\n",
       " ('@DARRENJ0NES', 1),\n",
       " ('sugar!', 1),\n",
       " ('farrrrr', 1),\n",
       " ('pdhpe', 1),\n",
       " ('bed.....got', 1),\n",
       " ('goose!', 1),\n",
       " ('TCI', 1),\n",
       " ('Wed.', 1),\n",
       " ('suprisingly', 1),\n",
       " ('goodbyes', 1),\n",
       " ('mcr....glad', 1),\n",
       " ('yeyah...but', 1),\n",
       " ('fink', 1),\n",
       " ('i,m', 1),\n",
       " ('popeye', 1),\n",
       " ('2moz', 1),\n",
       " ('Thick', 1),\n",
       " ('huhu..', 1),\n",
       " ('http://poprl.com/1vN0', 1),\n",
       " ('@RWAneesa', 1),\n",
       " ('flight...', 1),\n",
       " ('@Ames1103', 1),\n",
       " ('sailed', 1),\n",
       " (\"CCO's\", 1),\n",
       " ('thank/', 1),\n",
       " ('@wonky73', 1),\n",
       " ('DVR', 1),\n",
       " ('ANTM', 1),\n",
       " ('come...ha', 1),\n",
       " ('@ppittman', 1),\n",
       " ('Yays!!!', 1),\n",
       " ('boulevard', 1),\n",
       " ('dream,', 1),\n",
       " ('Hinder:', 1),\n",
       " ('angel,', 1),\n",
       " (\"Demi's\", 1),\n",
       " ('bed...sorta.', 1),\n",
       " ('to;', 1),\n",
       " ('@arsc', 1),\n",
       " ('burguer', 1),\n",
       " ('Dilemma,', 1),\n",
       " ('wear:', 1),\n",
       " ('Now:', 1),\n",
       " ('SanFran', 1),\n",
       " ('Foggy', 1),\n",
       " ('cple', 1),\n",
       " ('86', 1),\n",
       " ('degr', 1),\n",
       " ('FFA', 1),\n",
       " ('grin*', 1),\n",
       " ('wonï¿½t', 1),\n",
       " ('@hermorrine', 1),\n",
       " ('Spender.', 1),\n",
       " ('thumbnail', 1),\n",
       " ('TweetDeck?', 1),\n",
       " ('praline.', 1),\n",
       " ('@shakeitblueyes', 1),\n",
       " ('&quot;UP&quot;', 1),\n",
       " ('badly!', 1),\n",
       " ('Durham', 1),\n",
       " ('Greensboro', 1),\n",
       " ('Cook-Outs', 1),\n",
       " ('hmmmm....', 1),\n",
       " ('starting.', 1),\n",
       " ('colds!!', 1),\n",
       " ('Dallas..', 1),\n",
       " ('ow!?', 1),\n",
       " ('Hey...', 1),\n",
       " ('Chex-Quest!', 1),\n",
       " ('sins', 1),\n",
       " ('matilda', 1),\n",
       " ('@philcampbell', 1),\n",
       " ('skies?', 1),\n",
       " ('where,', 1),\n",
       " ('hazy', 1),\n",
       " ('Yours', 1),\n",
       " ('http://blip.fm/~5jo4w', 1),\n",
       " ('@acummings', 1),\n",
       " ('lieu', 1),\n",
       " ('...so', 1),\n",
       " ('lockbox', 1),\n",
       " ('MITO', 1),\n",
       " (\"dvd's\", 1),\n",
       " ('@julnas', 1),\n",
       " ('driver...', 1),\n",
       " ('tattooed', 1),\n",
       " ('Drinks', 1),\n",
       " ('Lori', 1),\n",
       " ('moms?!', 1),\n",
       " ('@HockeyTShirt', 1),\n",
       " ('Laughter', 1),\n",
       " ('Grabbing', 1),\n",
       " (\"chili's,\", 1),\n",
       " ('Got2meet', 1),\n",
       " ('brandon', 1),\n",
       " ('rhyder!', 1),\n",
       " ('@pattymlt', 1),\n",
       " (\"y'all!),\", 1),\n",
       " ('lawnmower...', 1),\n",
       " ('twitterberry.', 1),\n",
       " ('convenient.', 1),\n",
       " ('upset....', 1),\n",
       " ('@HDEnvy', 1),\n",
       " ('EU', 1),\n",
       " ('provider,', 1),\n",
       " ('@Squallee', 1),\n",
       " ('carys', 1),\n",
       " ('donna', 1),\n",
       " ('hugely', 1),\n",
       " ('already!!!', 1),\n",
       " ('(Yes', 1),\n",
       " ('hours)', 1),\n",
       " ('haaa..waaaah', 1),\n",
       " ('@gilv', 1),\n",
       " ('@DoperahStyles', 1),\n",
       " ('promoting', 1),\n",
       " ('muzik...not', 1),\n",
       " ('lmaao', 1),\n",
       " ('@ShutterBugGeek', 1),\n",
       " ('Nooo,', 1),\n",
       " ('Heehee.', 1),\n",
       " ('Shadduppp.', 1),\n",
       " ('@noiselesssound', 1),\n",
       " ('Regina', 1),\n",
       " ('deux!', 1),\n",
       " ('should/have', 1),\n",
       " ('mc!', 1),\n",
       " ('@jpdonga', 1),\n",
       " ('@krigeren', 1),\n",
       " ('@ikostar', 1),\n",
       " ('monetize', 1),\n",
       " ('differentiated', 1),\n",
       " ('pay/nopay.', 1),\n",
       " ('Dawson', 1),\n",
       " ('Titanic', 1),\n",
       " ('Miley?im', 1),\n",
       " ('amazing.tell', 1),\n",
       " ('I&lt;3Him!', 1),\n",
       " ('owm', 1),\n",
       " ('tryinh', 1),\n",
       " ('o2', 1),\n",
       " ('Eh..', 1),\n",
       " ('principled', 1),\n",
       " ('@AYoungOne', 1),\n",
       " ('Potbelly', 1),\n",
       " ('Chi-town', 1),\n",
       " ('@PotbellySdchWks', 1),\n",
       " ('@MamiTica', 1),\n",
       " ('whatï¿½s', 1),\n",
       " (\"&quot;NAPPY'S&quot;\", 1),\n",
       " ('&quot;N&quot;', 1),\n",
       " ('word....by', 1),\n",
       " ('iLove', 1),\n",
       " ('&quot;NAPPY&quot;', 1),\n",
       " ('braids', 1),\n",
       " ('iGot', 1),\n",
       " ('&quot;HANG-TIME&quot;', 1),\n",
       " ('@Fran_v', 1),\n",
       " ('morgannnn', 1),\n",
       " ('jumbo', 1),\n",
       " ('therapy,', 1),\n",
       " ('AHHH.....gimme', 1),\n",
       " ('geebus', 1),\n",
       " ('*head', 1),\n",
       " ('desk*', 1),\n",
       " ('yeh....its', 1),\n",
       " ('#lupus', 1),\n",
       " ('thro', 1),\n",
       " ('night...finally', 1),\n",
       " ('astroturf', 1),\n",
       " ('@mgrocki.', 1),\n",
       " ('drain.', 1),\n",
       " ('@tanmaygolhar', 1),\n",
       " ('@RobynLouise1993', 1),\n",
       " ('@leahstakes', 1),\n",
       " ('@jewlear', 1),\n",
       " ('@Celenko', 1),\n",
       " ('@sarahbeeny', 1),\n",
       " ('things.......I', 1),\n",
       " ('thinking!', 1),\n",
       " ('Studying', 1),\n",
       " ('morrow', 1),\n",
       " ('@chupacharged', 1),\n",
       " ('sly,', 1),\n",
       " ('@_AlexaJordan', 1),\n",
       " ('Cinema', 1),\n",
       " ('&quot;Knowing&quot;', 1),\n",
       " ('@assrocket', 1),\n",
       " ('trolling', 1),\n",
       " ('#right', 1),\n",
       " ('@lindentreephoto', 1),\n",
       " ('Pirate', 1),\n",
       " ('peaky.', 1),\n",
       " ('Paperboy', 1),\n",
       " ('console', 1),\n",
       " ('@Dreaming_awake', 1),\n",
       " ('MIDDAY.', 1),\n",
       " ('Stanley...', 1),\n",
       " ('GCSE', 1),\n",
       " ('@mbm88', 1),\n",
       " ('Tty', 1),\n",
       " ('chalks', 1),\n",
       " ('@CandyMaize', 1),\n",
       " ('ok..i', 1),\n",
       " ('ignored', 1),\n",
       " ('330pm.', 1),\n",
       " ('WINE!', 1),\n",
       " ('Johnny', 1),\n",
       " ('disappointed..mahirap', 1),\n",
       " ('mag-supervise', 1),\n",
       " ('tao..', 1),\n",
       " ('http://plurk.com/p/wxqwa', 1),\n",
       " ('having,', 1),\n",
       " ('ramen,', 1),\n",
       " ('@RainbowEagle', 1),\n",
       " ('replied!!', 1),\n",
       " ('laaazy', 1),\n",
       " (\"didnt'\", 1),\n",
       " ('@WeAreBrave', 1),\n",
       " ('@OatsAreRealFine', 1),\n",
       " ('have..really', 1),\n",
       " ('@jerrytrainor', 1),\n",
       " ('ICarly', 1),\n",
       " ('@aziraA', 1),\n",
       " ('YEAYYY!', 1),\n",
       " ('0930', 1),\n",
       " ('@fankri', 1),\n",
       " ('WORE', 1),\n",
       " ('OUT!!!', 1),\n",
       " ('@angelicaaa', 1),\n",
       " ('workies', 1),\n",
       " ('dad?', 1),\n",
       " ('exams?', 1),\n",
       " ('@godlessgirl', 1),\n",
       " ('jealousy', 1),\n",
       " ('2morrow.', 1),\n",
       " ('represents', 1),\n",
       " ('free-thinking', 1),\n",
       " ('1:36', 1),\n",
       " ('nasal', 1),\n",
       " ('trimmer', 1),\n",
       " ('@sensonize', 1),\n",
       " ('@PheenX', 1),\n",
       " ('crud', 1),\n",
       " ('blows!!!', 1),\n",
       " ('@svickn', 1),\n",
       " (\"G'morning!\", 1),\n",
       " ('Xbox', 1),\n",
       " ('ghetto?', 1),\n",
       " ('@amy_p', 1),\n",
       " ('@jamiedelaine', 1),\n",
       " ('lie...', 1),\n",
       " ('@Rliversidge', 1),\n",
       " ('@mumof_3girls', 1),\n",
       " ('LOUISE', 1),\n",
       " ('ballet', 1),\n",
       " ('cocktails', 1),\n",
       " ('Amritsar', 1),\n",
       " ('places)...the', 1),\n",
       " ('horror..hoping', 1),\n",
       " ('wholesale', 1),\n",
       " ('@Personal_Trainr', 1),\n",
       " ('@KatieKilljoy', 1),\n",
       " ('*pout,', 1),\n",
       " ('pout', 1),\n",
       " ('face*', 1),\n",
       " ('@dopenhagen', 1),\n",
       " ('KL?', 1),\n",
       " ('close!', 1),\n",
       " ('@xCUNHAx', 1),\n",
       " ('yea?', 1),\n",
       " ('@LisaTheDiva', 1),\n",
       " ('@melissa_hope', 1),\n",
       " ('.i', 1),\n",
       " ('@niw', 1),\n",
       " ('enable', 1),\n",
       " ('duped', 1),\n",
       " ('notifications', 1),\n",
       " ('kanye', 1),\n",
       " (\"V's\", 1),\n",
       " ('minute...i', 1),\n",
       " ('...gtta', 1),\n",
       " ('same!!!', 1),\n",
       " ('sweden', 1),\n",
       " ('@chescaaaaaa', 1),\n",
       " ('yeaaaahh.', 1),\n",
       " ('@musicjunkie11', 1),\n",
       " (\"Alright,It's\", 1),\n",
       " ('Ok-Ashley', 1),\n",
       " ('Travolta', 1),\n",
       " ('@jgreco4', 1),\n",
       " ('mother!', 1),\n",
       " ('http://bit.ly/1aa1RF', 1),\n",
       " (\"weather's...\", 1),\n",
       " ('asthma.', 1),\n",
       " ('Ventolin.', 1),\n",
       " ('Myst', 1),\n",
       " ('maze', 1),\n",
       " ('exports', 1),\n",
       " ('@AC_1', 1),\n",
       " ('Andrew!', 1),\n",
       " ('booo..', 1),\n",
       " ('flu..', 1),\n",
       " ('Beside,', 1),\n",
       " ('with!!', 1),\n",
       " ('@HandiQuilterBG', 1),\n",
       " ('dozen.', 1),\n",
       " (\"d'iberville.\", 1),\n",
       " ('Phail.', 1),\n",
       " ('smiled', 1),\n",
       " ('company..me', 1),\n",
       " ('army?', 1),\n",
       " ('@simplecake', 1),\n",
       " ('@GatorBat44', 1),\n",
       " ('aj', 1),\n",
       " ('sense,hahaha.', 1),\n",
       " ('colin!', 1),\n",
       " ('Hiiiiii!', 1),\n",
       " ('#Stud-Life:', 1),\n",
       " ('Tiberiu', 1),\n",
       " ('Lovin', 1),\n",
       " ('noi.', 1),\n",
       " ('aflat', 1),\n",
       " ('sunt', 1),\n",
       " ('imbecili', 1),\n",
       " ('peste', 1),\n",
       " ('tot.', 1),\n",
       " ('@franksting', 1),\n",
       " ('http://tr.im/kWOD', 1),\n",
       " ('@angryfaggot,', 1),\n",
       " ('Decaf?', 1),\n",
       " ('teas', 1),\n",
       " ('coffee-', 1),\n",
       " ('fjdskal', 1),\n",
       " ('Lincoln', 1),\n",
       " ('Square,', 1),\n",
       " ('Hahaha...gutted', 1),\n",
       " ('soon,so', 1),\n",
       " ('MM', 1),\n",
       " ('mums!!!!', 1),\n",
       " ('#mamam', 1),\n",
       " ('Hallooo', 1),\n",
       " ('bayern!hallooo', 1),\n",
       " ('stau!', 1),\n",
       " ('@kimgoss', 1),\n",
       " ('spades', 1),\n",
       " ('chillin..', 1),\n",
       " ('plurking.', 1),\n",
       " ('http://plurk.com/p/wxion', 1),\n",
       " ('@CaitiCaitlin', 1),\n",
       " ('bazillions', 1),\n",
       " ('boating/songwriting', 1),\n",
       " ('Cod..', 1),\n",
       " ('pleaase', 1),\n",
       " ('ftsk.', 1),\n",
       " ('tooooooo', 1),\n",
       " ('unto', 1),\n",
       " ('andy...went', 1),\n",
       " ('soup...but', 1),\n",
       " ('d&amp;d', 1),\n",
       " ('...is', 1),\n",
       " ('men,', 1),\n",
       " ('ACABOU!!!', 1),\n",
       " ('lovesick', 1),\n",
       " ('incidents', 1),\n",
       " ('Zippys', 1),\n",
       " ('candace!', 1),\n",
       " (\"this...it's\", 1),\n",
       " ('Snowball', 1),\n",
       " ('day...I', 1),\n",
       " ('http://tinyurl.com/37wt5f', 1),\n",
       " ('ï¿½ureo', 1),\n",
       " ('i-phones,', 1),\n",
       " ('Janeiro,', 1),\n",
       " ('valentines', 1),\n",
       " ('Brazil.', 1),\n",
       " ('lied!', 1),\n",
       " ('longer!!', 1),\n",
       " ('@agentwill', 1),\n",
       " ('odour', 1),\n",
       " ('@serenajwilliams', 1),\n",
       " ('Serena', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word freqdist\n",
    "fdist = FreqDist(tokenised_corpus)\n",
    "fdist.most_common(50)\n",
    "sorted(fdist.most_common(), key = lambda x: x[1], reverse= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All dem stop words... can add into the stopwords library for text preprocessing later. Some stopwords may have sentimental values ie to say, good, not etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for preprocessing\n",
    "def lowercase(text):\n",
    "    return [word.lower() for word in text]\n",
    "\n",
    "def remove_non_letters(text):\n",
    "    return [re.sub('[^a-z\\s]', '', word) for word in text]\n",
    "\n",
    "def tokenizer(text):\n",
    "    return text.split(' ')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "def lemmatization(text):\n",
    "    # Lemmatization (it's almost always better than stemming...)\n",
    "    return [lemmatizer.lemmatize(word) for word in text]\n",
    "\n",
    "nltk_stopwords = stopwords.words(\"english\")\n",
    "spacy_stopwords = list(STOP_WORDS)\n",
    "final_stopwords = list(set(nltk_stopwords + spacy_stopwords))\n",
    "def remove_stopword(text):\n",
    "    return [word for word in text if word not in final_stopwords]\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    return [word for word in text if word != '']\n",
    "\n",
    "def remove_handle(text):\n",
    "    return [word for word in text if '@' not in word]\n",
    "\n",
    "def convert_to_string(text):\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [@bex_1210, holy, crap,, i, need, to, see, tha...\n",
      "1        [happy, mother's, day, to, all, of, the, wonde...\n",
      "2        [wishing, i, could, be, in, nola, this, weeken...\n",
      "3        [what, a, day!, #dayofservice, completed,, and...\n",
      "4        [@jamesmurphy, anything, to, sell, an, album.,...\n",
      "                               ...                        \n",
      "23995    [i, have, been, playing, skate, for, two, hour...\n",
      "23996    [im, wearing, a, certain, tye, dye, tshirt, at...\n",
      "23997                  [@deepaprabhu, thanks, and, thanks]\n",
      "23998    [@scottisafool, , i, had, a, analog, tuner, th...\n",
      "23999    [just, watched, the, &quot;final, break&quot;,...\n",
      "Name: content, Length: 24000, dtype: object\n",
      "0        [holy, crap, i, need, to, see, that, too, bad,...\n",
      "1        [happy, mothers, day, to, all, of, the, wonder...\n",
      "2        [wishing, i, could, be, in, nola, this, weeken...\n",
      "3        [what, a, day, dayofservice, completed, and, n...\n",
      "4             [anything, to, sell, an, album, poor, thing]\n",
      "                               ...                        \n",
      "23995    [i, have, been, playing, skate, for, two, hour...\n",
      "23996    [im, wearing, a, certain, tye, dye, tshirt, at...\n",
      "23997                                [thanks, and, thanks]\n",
      "23998    [, i, had, a, analog, tuner, the, mc, team, ga...\n",
      "23999    [just, watched, the, quotfinal, breakquot, fin...\n",
      "Name: content, Length: 24000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['content'] = df['content'].apply(tokenizer)\n",
    "df['content'] = df['content'].apply(lowercase)\n",
    "print(df['content'] )\n",
    "\n",
    "df['content'] = df['content'].apply(remove_handle)\n",
    "df['content'] = df['content'].apply(remove_non_letters)\n",
    "print(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(remove_stopword)\n",
    "df['content'] = df['content'].apply(lemmatization)\n",
    "df['content'] = df['content'].apply(remove_stopword)\n",
    "df['content'] = df['content'].apply(remove_whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [holy, crap, need, bad, gotta, wait, tomorrow]\n",
       "1        [happy, mother, day, wonderful, woman, great, ...\n",
       "2               [wishing, nola, weekend, oh, ill, tuesday]\n",
       "3        [day, dayofservice, completed, aching, clearin...\n",
       "4                               [sell, album, poor, thing]\n",
       "                               ...                        \n",
       "23995    [playing, skate, hour, need, actually, skate, ...\n",
       "23996    [im, wearing, certain, tye, dye, tshirt, momen...\n",
       "23997                                     [thanks, thanks]\n",
       "23998    [analog, tuner, mc, team, gave, year, ago, inb...\n",
       "23999    [watched, quotfinal, breakquot, final, prison,...\n",
       "Name: content, Length: 24000, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236736\n"
     ]
    }
   ],
   "source": [
    "words_list = words.words()\n",
    "print(len(words_list))\n",
    "def filter_gibberish(text):\n",
    "    return [word for word in text if word in words_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(filter_gibberish)\n",
    "\n",
    "df['content'] = df['content'].apply(convert_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         holy crap need bad wait tomorrow\n",
       "1               happy mother day wonderful woman great day\n",
       "2                                   wishing weekend oh ill\n",
       "3        day aching clearing tree beautiful lake splitt...\n",
       "4                                    sell album poor thing\n",
       "                               ...                        \n",
       "23995                  skate hour need actually skate late\n",
       "23996      wearing certain tye dye moment miss counterpart\n",
       "23997                                        thanks thanks\n",
       "23998       tuner team gave year ago driver handled driver\n",
       "23999    watched final prison break episode great farew...\n",
       "Name: content, Length: 24000, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing\n",
    "1. tf-idf\n",
    "2. encoding sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Encoding Sentiments\n",
    "def sentiments_encoding(sentiment):\n",
    "    sentiments = ['happy', 'sad', 'neutral', 'fury']\n",
    "    return sentiments.index(sentiment)\n",
    "\n",
    "df['sentiment'] = df['sentiment'].apply(sentiments_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9180\n",
       "1    8174\n",
       "2    5786\n",
       "3     860\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>holy crap need bad wait tomorrow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy mother day wonderful woman great day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wishing weekend oh ill</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>day aching clearing tree beautiful lake splitt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sell album poor thing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  sentiment\n",
       "0                   holy crap need bad wait tomorrow          0\n",
       "1         happy mother day wonderful woman great day          0\n",
       "2                             wishing weekend oh ill          0\n",
       "3  day aching clearing tree beautiful lake splitt...          0\n",
       "4                              sell album poor thing          1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23240 entries, 0 to 23999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   content    23240 non-null  object\n",
      " 1   sentiment  23240 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 544.7+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"cleaned.csv\")\n",
    "test_df.drop('Unnamed: 0', axis= 1, inplace= True)\n",
    "test_df.dropna(axis=0, inplace= True)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aba</th>\n",
       "      <th>abalone</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>abiding</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>...</th>\n",
       "      <th>za</th>\n",
       "      <th>zac</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeta</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zip</th>\n",
       "      <th>zo</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23235</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23236</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23238</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23239</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23240 rows × 8285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aba  abalone  abandon  abandoned  abbreviate  abiding  ability  \\\n",
       "0       0    0        0        0          0           0        0        0   \n",
       "1       0    0        0        0          0           0        0        0   \n",
       "2       0    0        0        0          0           0        0        0   \n",
       "3       0    0        0        0          0           0        0        0   \n",
       "4       0    0        0        0          0           0        0        0   \n",
       "...    ..  ...      ...      ...        ...         ...      ...      ...   \n",
       "23235   0    0        0        0          0           0        0        0   \n",
       "23236   0    0        0        0          0           0        0        0   \n",
       "23237   0    0        0        0          0           0        0        0   \n",
       "23238   0    0        0        0          0           0        0        0   \n",
       "23239   0    0        0        0          0           0        0        0   \n",
       "\n",
       "       able  abnormal  ...  za  zac  zero  zeta  zimbabwe  zip  zo  zombie  \\\n",
       "0         0         0  ...   0    0     0     0         0    0   0       0   \n",
       "1         0         0  ...   0    0     0     0         0    0   0       0   \n",
       "2         0         0  ...   0    0     0     0         0    0   0       0   \n",
       "3         0         0  ...   0    0     0     0         0    0   0       0   \n",
       "4         0         0  ...   0    0     0     0         0    0   0       0   \n",
       "...     ...       ...  ...  ..  ...   ...   ...       ...  ...  ..     ...   \n",
       "23235     0         0  ...   0    0     0     0         0    0   0       0   \n",
       "23236     0         0  ...   0    0     0     0         0    0   0       0   \n",
       "23237     0         0  ...   0    0     0     0         0    0   0       0   \n",
       "23238     0         0  ...   0    0     0     0         0    0   0       0   \n",
       "23239     0         0  ...   0    0     0     0         0    0   0       0   \n",
       "\n",
       "       zone  zoo  \n",
       "0         0    0  \n",
       "1         0    0  \n",
       "2         0    0  \n",
       "3         0    0  \n",
       "4         0    0  \n",
       "...     ...  ...  \n",
       "23235     0    0  \n",
       "23236     0    0  \n",
       "23237     0    0  \n",
       "23238     0    0  \n",
       "23239     0    0  \n",
       "\n",
       "[23240 rows x 8285 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare word vector \n",
    "cv = CountVectorizer()\n",
    "words_sparse_matrix = cv.fit_transform(test_df['content'])\n",
    "sparse_df = pd.DataFrame(columns= list(cv.get_feature_names()), data= words_sparse_matrix.A)\n",
    "sparse_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.3.1\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Flatten, Conv1D, MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "print(\"Version: \", tf.__version__) # Check tf version\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\") # Check GPU status\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU') # Config GPU\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aba</th>\n",
       "      <th>abalone</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>abiding</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>...</th>\n",
       "      <th>za</th>\n",
       "      <th>zac</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeta</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zip</th>\n",
       "      <th>zo</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23235</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23236</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23238</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23239</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23240 rows × 8285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aba  abalone  abandon  abandoned  abbreviate  abiding  ability  \\\n",
       "0       0    0        0        0          0           0        0        0   \n",
       "1       0    0        0        0          0           0        0        0   \n",
       "2       0    0        0        0          0           0        0        0   \n",
       "3       0    0        0        0          0           0        0        0   \n",
       "4       0    0        0        0          0           0        0        0   \n",
       "...    ..  ...      ...      ...        ...         ...      ...      ...   \n",
       "23235   0    0        0        0          0           0        0        0   \n",
       "23236   0    0        0        0          0           0        0        0   \n",
       "23237   0    0        0        0          0           0        0        0   \n",
       "23238   0    0        0        0          0           0        0        0   \n",
       "23239   0    0        0        0          0           0        0        0   \n",
       "\n",
       "       able  abnormal  ...  za  zac  zero  zeta  zimbabwe  zip  zo  zombie  \\\n",
       "0         0         0  ...   0    0     0     0         0    0   0       0   \n",
       "1         0         0  ...   0    0     0     0         0    0   0       0   \n",
       "2         0         0  ...   0    0     0     0         0    0   0       0   \n",
       "3         0         0  ...   0    0     0     0         0    0   0       0   \n",
       "4         0         0  ...   0    0     0     0         0    0   0       0   \n",
       "...     ...       ...  ...  ..  ...   ...   ...       ...  ...  ..     ...   \n",
       "23235     0         0  ...   0    0     0     0         0    0   0       0   \n",
       "23236     0         0  ...   0    0     0     0         0    0   0       0   \n",
       "23237     0         0  ...   0    0     0     0         0    0   0       0   \n",
       "23238     0         0  ...   0    0     0     0         0    0   0       0   \n",
       "23239     0         0  ...   0    0     0     0         0    0   0       0   \n",
       "\n",
       "       zone  zoo  \n",
       "0         0    0  \n",
       "1         0    0  \n",
       "2         0    0  \n",
       "3         0    0  \n",
       "4         0    0  \n",
       "...     ...  ...  \n",
       "23235     0    0  \n",
       "23236     0    0  \n",
       "23237     0    0  \n",
       "23238     0    0  \n",
       "23239     0    0  \n",
       "\n",
       "[23240 rows x 8285 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8303 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 50000\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(test_df['content'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (23240, 250)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23240, 4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(test_df['content'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)\n",
    "\n",
    "y = test_df['sentiment']\n",
    "y = to_categorical(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15570, 250) (15570, 4)\n",
      "(7670, 250) (7670, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 250, 50)           2500000   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12500)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               3200256   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 6,361,252\n",
      "Trainable params: 6,361,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=MAX_NB_WORDS, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss= 'binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "244/244 [==============================] - 9s 36ms/step - loss: 0.4930 - accuracy: 0.4279 - val_loss: 0.4685 - val_accuracy: 0.4996\n",
      "Epoch 2/50\n",
      "244/244 [==============================] - 9s 36ms/step - loss: 0.4367 - accuracy: 0.5556 - val_loss: 0.4579 - val_accuracy: 0.5047\n",
      "Epoch 3/50\n",
      "244/244 [==============================] - 9s 36ms/step - loss: 0.3697 - accuracy: 0.6469 - val_loss: 0.5004 - val_accuracy: 0.4993\n",
      "Epoch 4/50\n",
      "244/244 [==============================] - 9s 36ms/step - loss: 0.2948 - accuracy: 0.7328 - val_loss: 0.5384 - val_accuracy: 0.4866\n",
      "Epoch 5/50\n",
      "244/244 [==============================] - 9s 38ms/step - loss: 0.2341 - accuracy: 0.7979 - val_loss: 0.6221 - val_accuracy: 0.4725\n",
      "Epoch 6/50\n",
      "244/244 [==============================] - 9s 37ms/step - loss: 0.1891 - accuracy: 0.8368 - val_loss: 0.7207 - val_accuracy: 0.4700\n",
      "Epoch 7/50\n",
      "244/244 [==============================] - 9s 36ms/step - loss: 0.1625 - accuracy: 0.8597 - val_loss: 0.7970 - val_accuracy: 0.4630\n",
      "Epoch 8/50\n",
      "244/244 [==============================] - 9s 36ms/step - loss: 0.1443 - accuracy: 0.8723 - val_loss: 0.8904 - val_accuracy: 0.4661\n",
      "Epoch 9/50\n",
      "244/244 [==============================] - 9s 36ms/step - loss: 0.1326 - accuracy: 0.8794 - val_loss: 0.9452 - val_accuracy: 0.4691\n",
      "Epoch 10/50\n",
      "244/244 [==============================] - 9s 38ms/step - loss: 0.1238 - accuracy: 0.8870 - val_loss: 0.8978 - val_accuracy: 0.4515\n",
      "Epoch 11/50\n",
      "244/244 [==============================] - 9s 36ms/step - loss: 0.1174 - accuracy: 0.8924 - val_loss: 1.2060 - val_accuracy: 0.4636\n",
      "Epoch 12/50\n",
      "244/244 [==============================] - 9s 37ms/step - loss: 0.1098 - accuracy: 0.8982 - val_loss: 1.3789 - val_accuracy: 0.4592\n",
      "Epoch 13/50\n",
      "244/244 [==============================] - 9s 37ms/step - loss: 0.1081 - accuracy: 0.8987 - val_loss: 1.3609 - val_accuracy: 0.4690\n",
      "Epoch 14/50\n",
      "244/244 [==============================] - 9s 37ms/step - loss: 0.1013 - accuracy: 0.9042 - val_loss: 1.3967 - val_accuracy: 0.4520\n",
      "Epoch 15/50\n",
      "244/244 [==============================] - 9s 37ms/step - loss: 0.0994 - accuracy: 0.9061 - val_loss: 1.2232 - val_accuracy: 0.4600\n",
      "Epoch 16/50\n",
      "244/244 [==============================] - 9s 36ms/step - loss: 0.1010 - accuracy: 0.9069 - val_loss: 1.3568 - val_accuracy: 0.4551\n",
      "Epoch 17/50\n",
      "244/244 [==============================] - 9s 36ms/step - loss: 0.0943 - accuracy: 0.9120 - val_loss: 1.5115 - val_accuracy: 0.4631\n",
      "Epoch 18/50\n",
      "244/244 [==============================] - 9s 36ms/step - loss: 0.0949 - accuracy: 0.9100 - val_loss: 1.6443 - val_accuracy: 0.4587\n",
      "Epoch 19/50\n",
      "244/244 [==============================] - 9s 37ms/step - loss: 0.0919 - accuracy: 0.9110 - val_loss: 1.4769 - val_accuracy: 0.4563\n",
      "Epoch 20/50\n",
      "244/244 [==============================] - 9s 37ms/step - loss: 0.0877 - accuracy: 0.9150 - val_loss: 1.8431 - val_accuracy: 0.4565\n",
      "Epoch 21/50\n",
      "244/244 [==============================] - 9s 37ms/step - loss: 0.0869 - accuracy: 0.9162 - val_loss: 1.6167 - val_accuracy: 0.4592\n",
      "Epoch 22/50\n",
      "244/244 [==============================] - 9s 36ms/step - loss: 0.0852 - accuracy: 0.9195 - val_loss: 1.8062 - val_accuracy: 0.4551\n",
      "Epoch 23/50\n",
      "244/244 [==============================] - 9s 37ms/step - loss: 0.0827 - accuracy: 0.9202 - val_loss: 1.7584 - val_accuracy: 0.4576\n",
      "Epoch 24/50\n",
      "217/244 [=========================>....] - ETA: 0s - loss: 0.0798 - accuracy: 0.9235"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-ba70fdbc9e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     batch_size= 64)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size= 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict()\n",
    "prediction = pd.DataFrame(predictions, columns=['predictions']).to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
